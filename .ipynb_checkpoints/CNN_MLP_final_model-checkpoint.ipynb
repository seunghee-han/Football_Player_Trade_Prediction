{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17dc0509",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "id": "vgx1wrSM_VYm",
    "outputId": "e81a0fcc-dfb1-4d33-8f53-ac7819b7d510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.6492 | Val Loss: 0.6504\n",
      "[Epoch 2] Train Loss: 0.6288 | Val Loss: 0.6358\n",
      "[Epoch 3] Train Loss: 0.6199 | Val Loss: 0.6174\n",
      "[Epoch 4] Train Loss: 0.6095 | Val Loss: 0.6120\n",
      "[Epoch 5] Train Loss: 0.6008 | Val Loss: 0.6089\n",
      "[Epoch 6] Train Loss: 0.5877 | Val Loss: 0.5979\n",
      "[Epoch 7] Train Loss: 0.5734 | Val Loss: 0.5893\n",
      "[Epoch 8] Train Loss: 0.5579 | Val Loss: 0.5880\n",
      "[Epoch 9] Train Loss: 0.5373 | Val Loss: 0.5672\n",
      "[Epoch 10] Train Loss: 0.5153 | Val Loss: 0.5614\n",
      "[Epoch 11] Train Loss: 0.4874 | Val Loss: 0.5547\n",
      "[Epoch 12] Train Loss: 0.4555 | Val Loss: 0.5339\n",
      "[Epoch 13] Train Loss: 0.4258 | Val Loss: 0.5469\n",
      "[Epoch 14] Train Loss: 0.4005 | Val Loss: 0.5333\n",
      "[Epoch 15] Train Loss: 0.3642 | Val Loss: 0.5346\n",
      "[Epoch 16] Train Loss: 0.3381 | Val Loss: 0.5242\n",
      "[Epoch 17] Train Loss: 0.3113 | Val Loss: 0.5058\n",
      "[Epoch 18] Train Loss: 0.2851 | Val Loss: 0.5509\n",
      "[Epoch 19] Train Loss: 0.2609 | Val Loss: 0.5608\n",
      "[Epoch 20] Train Loss: 0.2430 | Val Loss: 0.5484\n",
      "[Epoch 21] Train Loss: 0.2245 | Val Loss: 0.5272\n",
      "[Epoch 22] Train Loss: 0.2093 | Val Loss: 0.5508\n",
      "[Epoch 23] Train Loss: 0.1943 | Val Loss: 0.5395\n",
      "[Epoch 24] Train Loss: 0.1807 | Val Loss: 0.5475\n",
      "[Epoch 25] Train Loss: 0.1724 | Val Loss: 0.5677\n",
      "[Epoch 26] Train Loss: 0.1596 | Val Loss: 0.5958\n",
      "[Epoch 27] Train Loss: 0.1519 | Val Loss: 0.5575\n",
      "[Epoch 28] Train Loss: 0.1400 | Val Loss: 0.6140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3-1136296143.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Dataset 정의\n",
    "# -----------------------\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values if isinstance(y, pd.Series) else y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super().__init__()\n",
    "        stride = 2 if downsample else 1\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.proj = (\n",
    "            nn.Conv1d(in_channels, out_channels, 1, stride=stride) if downsample or in_channels!=out_channels else nn.Identity()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        identity = self.proj(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "class ImprovedCNN1DClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.initial_bn = nn.BatchNorm1d(input_dim)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResidualBlock1D(64, 128, downsample=True),\n",
    "            ResidualBlock1D(128, 256, downsample=True),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# -----------------------\n",
    "# 데이터 로드\n",
    "# -----------------------\n",
    "x_train = pd.read_csv(\"./x.csv\")\n",
    "y_train = pd.read_csv(\"./y.csv\")\n",
    "\n",
    "# 클래스 정수형 확인\n",
    "y_train = y_train.squeeze()\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "# 표준화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_train)\n",
    "\n",
    "# 훈련/검증 분리\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(X_resampled, y_resampled, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = TabularDataset(X_train, y_train_split)\n",
    "val_dataset = TabularDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True) #->64->128\n",
    "val_loader = DataLoader(val_dataset, batch_size=256) # 64->128\n",
    "\n",
    "# -----------------------\n",
    "# 모델 설정\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImprovedCNN1DClassifier(input_dim=x_train.shape[1]).to(device)\n",
    "\n",
    "# pos_weight 계산\n",
    "labels = np.unique(y_train_split)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=labels, y=y_train_split)\n",
    "weight_dict = dict(zip(labels, class_weights))\n",
    "pos_weight = torch.tensor([weight_dict[1] / weight_dict[0]]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  ##4->3\n",
    "\n",
    "train_losses =[]\n",
    "val_losses =[]\n",
    "\n",
    "# -----------------------\n",
    "# 학습\n",
    "# -----------------------\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # 검증 손실\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            val_loss += criterion(logits, y_batch).item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "torch.save(model.state_dict(), './CNN_MLP_final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9e5df",
   "metadata": {
    "id": "r-5faMDYkKav"
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 평가\n",
    "# -----------------------\n",
    "model.eval()\n",
    "all_probs, all_targets = [], []\n",
    "thresholds = []\n",
    "recalls_0 = []\n",
    "recalls_1 = []\n",
    "accs = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits = model(X_batch)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_targets.extend(y_batch.numpy())\n",
    "\n",
    "all_probs = np.array(all_probs).flatten()\n",
    "all_targets = np.array(all_targets).flatten()\n",
    "\n",
    "# Threshold 튜닝\n",
    "best_f1, best_thresh = 0, 0\n",
    "for t in np.arange(0.1, 0.9, 0.01):\n",
    "    preds = (all_probs > t).astype(int)\n",
    "    f1 = f1_score(all_targets, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "# 최종 예측\n",
    "final_preds = (all_probs > best_thresh).astype(int)\n",
    "acc = accuracy_score(all_targets, final_preds)\n",
    "report = classification_report(all_targets, final_preds, digits=4)\n",
    "\n",
    "print(f\"\\n✅ Best Threshold: {best_thresh:.2f}\")\n",
    "print(f\"✅ Accuracy       : {acc:.4f}\")\n",
    "print(f\"✅ F1 Score       : {best_f1:.4f}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b70f1",
   "metadata": {
    "id": "HeF_Ex83jus_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for thresh in thresholds:\n",
    "    preds = (all_probs > thresh).astype(int)\n",
    "    acc = accuracy_score(all_targets, preds)\n",
    "    recall_0 = recall_score(all_targets, preds, pos_label=0)\n",
    "    recall_1 = recall_score(all_targets, preds, pos_label=1)\n",
    "    accs.append(acc)\n",
    "    recalls_0.append(recall_0)\n",
    "    recalls_1.append(recall_1)\n",
    "# Plot with dual y-axis\n",
    "fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Recall', color=color)\n",
    "ax1.plot(thresholds, recalls_0, marker='o', label='Recall (Class 0)', color='blue')\n",
    "ax1.plot(thresholds, recalls_1, marker='o', label='Recall (Class 1)', color='red')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(loc='upper left')\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "ax2.plot(thresholds, accs, marker='s', label='Accuracy', color='green')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title('Recall (per class) and Accuracy vs. Threshold')\n",
    "plt.xticks(thresholds)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
