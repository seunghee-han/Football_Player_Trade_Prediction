{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2497d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "id": "vgx1wrSM_VYm",
    "outputId": "e81a0fcc-dfb1-4d33-8f53-ac7819b7d510"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Dataset 정의\n",
    "# -----------------------\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values if isinstance(y, pd.Series) else y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super().__init__()\n",
    "        stride = 2 if downsample else 1\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.proj = (\n",
    "            nn.Conv1d(in_channels, out_channels, 1, stride=stride) if downsample or in_channels!=out_channels else nn.Identity()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        identity = self.proj(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "class ImprovedCNN1DClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.initial_bn = nn.BatchNorm1d(input_dim)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResidualBlock1D(64, 128, downsample=True),\n",
    "            ResidualBlock1D(128, 256, downsample=True),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        return self.mlp(x)\n",
    "\n",
    "# -----------------------\n",
    "# 데이터 로드\n",
    "# -----------------------\n",
    "x_train = pd.read_csv(\"./x.csv\")\n",
    "y_train = pd.read_csv(\"./y.csv\")\n",
    "\n",
    "# 클래스 정수형 확인\n",
    "y_train = y_train.squeeze()\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "# 표준화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x_train)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_train)\n",
    "\n",
    "# 훈련/검증 분리\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(X_resampled, y_resampled, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = TabularDataset(X_train, y_train_split)\n",
    "val_dataset = TabularDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True) #->64->128\n",
    "val_loader = DataLoader(val_dataset, batch_size=256) # 64->128\n",
    "\n",
    "# -----------------------\n",
    "# 모델 설정\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImprovedCNN1DClassifier(input_dim=x_train.shape[1]).to(device)\n",
    "\n",
    "# pos_weight 계산\n",
    "labels = np.unique(y_train_split)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=labels, y=y_train_split)\n",
    "weight_dict = dict(zip(labels, class_weights))\n",
    "pos_weight = torch.tensor([weight_dict[1] / weight_dict[0]]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  ##4->3\n",
    "\n",
    "train_losses =[]\n",
    "val_losses =[]\n",
    "\n",
    "# -----------------------\n",
    "# 학습\n",
    "# -----------------------\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # 검증 손실\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            val_loss += criterion(logits, y_batch).item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "torch.save(model.state_dict(), './CNN_MLP_final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83c0f7",
   "metadata": {
    "id": "r-5faMDYkKav"
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 평가\n",
    "# -----------------------\n",
    "model.eval()\n",
    "all_probs, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        logits = model(X_batch)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_targets.extend(y_batch.numpy())\n",
    "\n",
    "all_probs = np.array(all_probs).flatten()\n",
    "all_targets = np.array(all_targets).flatten()\n",
    "\n",
    "# Threshold 튜닝\n",
    "best_f1, best_thresh = 0, 0\n",
    "for t in np.arange(0.1, 0.9, 0.01):\n",
    "    preds = (all_probs > t).astype(int)\n",
    "    f1 = f1_score(all_targets, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "# 최종 예측\n",
    "final_preds = (all_probs > best_thresh).astype(int)\n",
    "acc = accuracy_score(all_targets, final_preds)\n",
    "report = classification_report(all_targets, final_preds, digits=4)\n",
    "\n",
    "print(f\"\\n✅ Best Threshold: {best_thresh:.2f}\")\n",
    "print(f\"✅ Accuracy       : {acc:.4f}\")\n",
    "print(f\"✅ F1 Score       : {best_f1:.4f}\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
